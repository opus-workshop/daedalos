================================================================================
                           LSP-POOL - SPECIFICATION
                        Pre-warmed Language Server Pool
================================================================================

VERSION: 1.0.0
LICENSE: MIT
AUTHOR: Claude (Opus)
STATUS: Reference Specification

================================================================================
                                 PHILOSOPHY
================================================================================

"Intelligence should be instant."

Language Server Protocol (LSP) servers provide code intelligence: completions,
diagnostics, go-to-definition, and more. But they have a problem: startup time.

A TypeScript project might take 10-30 seconds to initialize its LSP. Python
with type checking can take even longer. This latency kills the AI workflow.

LSP-Pool solves this by:
  1. Pre-starting LSP servers before they're needed
  2. Keeping them warm and ready
  3. Intelligently predicting which servers you'll need
  4. Managing resources so your system doesn't melt

================================================================================
                               CORE CONCEPTS
================================================================================

SERVER POOL
-----------
A collection of running LSP servers, ready to serve requests immediately.

WARM VS COLD
------------
Warm: Server is running, project indexed, ready for queries (< 100ms response)
Cold: Server needs to start and index (seconds to minutes)

PREDICTIVE WARMING
------------------
The pool predicts which servers you'll need based on:
  - Recent project activity
  - File types in current directory
  - Time of day patterns
  - Git branch changes

RESOURCE MANAGEMENT
-------------------
LSP servers are memory-hungry. The pool manages resources by:
  - Limiting concurrent warm servers
  - Hibernating idle servers
  - Priority-based eviction

================================================================================
                              COMMAND INTERFACE
================================================================================

lsp-pool start
--------------
Start the LSP pool daemon.

Options:
  --max-servers <n>    Maximum concurrent servers (default: 5)
  --memory-limit <mb>  Memory limit for pool (default: 2048)
  --socket <path>      Unix socket path

lsp-pool stop
-------------
Stop the pool daemon (gracefully shuts down all servers).

lsp-pool status
---------------
Show pool status.

Output:
  LSP Pool Status: running
  Memory: 1.2GB / 2GB
  Servers: 3/5

  Warm Servers:
  LANGUAGE        PROJECT                     MEMORY    UPTIME     LAST QUERY
  typescript      ~/projects/webapp           450 MB    2h 15m     5s ago
  python          ~/projects/ml-pipeline      320 MB    45m        2m ago
  rust            ~/projects/cli-tool         280 MB    1h 30m     30m ago

  Queued for Warming:
  LANGUAGE        PROJECT                     REASON
  go              ~/projects/api              Recent activity
  python          ~/projects/scripts          Predicted (schedule)

lsp-pool warm <language> [path]
-------------------------------
Explicitly warm a server for a language/project.

Arguments:
  <language>          Language: typescript|python|rust|go|etc.
  [path]              Project path (default: current directory)

Options:
  --priority <p>      Priority: high|normal|low
  --wait              Wait for server to be ready

Examples:
  lsp-pool warm typescript ~/projects/webapp
  lsp-pool warm python --wait
  lsp-pool warm rust ./my-crate --priority high

lsp-pool cool <language> [path]
-------------------------------
Stop a specific server to free resources.

Options:
  --hibernate         Hibernate instead of stop (faster restart)

lsp-pool query <command> [args...]
----------------------------------
Send LSP query to appropriate server.

Commands:
  hover <file:line:col>           Get hover information
  definition <file:line:col>      Go to definition
  references <file:line:col>      Find all references
  completion <file:line:col>      Get completions
  diagnostics <file>              Get diagnostics for file
  symbols <file>                  Get document symbols
  workspace-symbols <query>       Search workspace symbols

Examples:
  lsp-pool query hover src/main.ts:42:15
  lsp-pool query definition lib/utils.py:100:5
  lsp-pool query completion src/app.rs:55:10
  lsp-pool query diagnostics src/index.ts

Options:
  --json              Output as JSON
  --timeout <ms>      Query timeout (default: 5000)

lsp-pool list
-------------
List all registered language servers.

Output:
  LANGUAGE        SERVER              STATUS      COMMAND
  typescript      typescript-language-server    available   npx typescript-language-server
  python          pyright             available   pyright-langserver
  rust            rust-analyzer       available   rust-analyzer
  go              gopls               available   gopls
  c/cpp           clangd              available   clangd
  java            jdtls               available   jdtls
  lua             lua-language-server available   lua-language-server

lsp-pool config <language> [--set KEY=VALUE]
--------------------------------------------
View or modify language server configuration.

Examples:
  lsp-pool config typescript
  lsp-pool config python --set python.analysis.typeCheckingMode=strict

lsp-pool logs [language]
------------------------
View server logs.

Options:
  --follow, -f        Follow log output
  --level <level>     Filter by level: error|warn|info|debug

lsp-pool predict
----------------
Show predicted server needs.

Output shows what the pool plans to warm and why:
  LANGUAGE        PROJECT                     CONFIDENCE   REASON
  typescript      ~/projects/webapp           95%          Active in last hour
  python          ~/projects/scripts          70%          Daily pattern (10am)
  go              ~/projects/api              60%          Branch checkout detected

================================================================================
                              CONFIGURATION
================================================================================

~/.config/daedalos/lsp-pool/config.yaml

```yaml
# LSP Pool Configuration

pool:
  max_servers: 5
  memory_limit_mb: 2048
  idle_timeout: 30m
  hibernate_timeout: 2h

prediction:
  enabled: true
  lookback_hours: 24
  confidence_threshold: 0.5

servers:
  typescript:
    command: npx typescript-language-server --stdio
    memory_estimate: 400
    init_timeout: 30s
    settings:
      typescript.preferences.importModuleSpecifier: relative

  python:
    command: pyright-langserver --stdio
    memory_estimate: 300
    init_timeout: 20s
    settings:
      python.analysis.typeCheckingMode: basic

  rust:
    command: rust-analyzer
    memory_estimate: 500
    init_timeout: 60s
    settings:
      rust-analyzer.checkOnSave.command: clippy

  go:
    command: gopls serve
    memory_estimate: 200
    init_timeout: 15s

  # Add more languages as needed
```

================================================================================
                         INTEGRATION WITH AGENTS
================================================================================

AI agents can query the pool directly:

```bash
# Agent needs hover info
result=$(lsp-pool query hover src/main.ts:42:15 --json)

# Agent needs completions
completions=$(lsp-pool query completion src/app.py:100:5 --json)

# Agent checks for errors
diagnostics=$(lsp-pool query diagnostics src/lib.rs --json)
```

For integrated agents (Claude Code, Cursor):
  - Pool runs in background
  - Agent's internal LSP queries routed through pool
  - Transparent speedup

================================================================================
                          PREDICTIVE WARMING
================================================================================

The pool learns your patterns and pre-warms servers:

Signals used:
  1. File access patterns (which projects you open)
  2. Time patterns (what you work on at what time)
  3. Git activity (branch switches, recent commits)
  4. Terminal history (cd commands, editor launches)
  5. Calendar integration (meeting-free blocks = coding time)

Prediction model:
  - Simple weighted history for v1
  - Can be upgraded to ML model later
  - Conservative (won't over-warm and waste resources)

================================================================================
                         RESOURCE MANAGEMENT
================================================================================

When resources are constrained:

1. PRIORITY RANKING
   - Currently active project: highest
   - Recently used: high
   - Predicted need: medium
   - Idle: low

2. EVICTION POLICY
   - Hibernate idle servers first (can restart quickly)
   - Cool low-priority servers
   - Never evict active server mid-query

3. MEMORY MONITORING
   - Track actual vs estimated memory
   - Alert if pool exceeds limit
   - Auto-evict to stay under limit

================================================================================
                              EXIT CODES
================================================================================

0   Success
1   General error
2   Server not found
3   Query timeout
4   Memory limit exceeded
5   Server crash
6   Pool not running

================================================================================
                           IMPLEMENTATION NOTES
================================================================================

Language: Python + Rust hybrid
  - Python for daemon and orchestration
  - Rust for performance-critical query routing

Dependencies:
  - Python 3.10+
  - pylsp (Python LSP library)
  - pyyaml
  - psutil (resource monitoring)
  - sqlite3 (prediction model storage)

Architecture:
  - Daemon manages server processes
  - Unix socket for agent communication
  - Separate process per language server
  - Query multiplexing for concurrent requests

================================================================================
