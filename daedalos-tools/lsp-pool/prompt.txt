================================================================================
                      LSP-POOL - ONE-SHOT BUILD PROMPT
================================================================================

You are building the `lsp-pool` tool for Daedalos, a Linux distribution designed
for AI-assisted development. LSP-Pool manages a pool of pre-warmed Language
Server Protocol servers.

================================================================================
                              WHAT YOU'RE BUILDING
================================================================================

LSP servers provide code intelligence (completions, diagnostics, go-to-definition)
but have slow startup times. LSP-Pool:
- Pre-starts servers before they're needed
- Keeps them warm and ready
- Predicts which servers you'll need
- Manages memory to prevent system overload

Result: Instant code intelligence instead of waiting 10-30 seconds.

================================================================================
                              ARCHITECTURE
================================================================================

Create these files:

lsp-pool/
├── lsp-pool                  # Main CLI entry point (Bash)
├── lsppool/
│   ├── __init__.py
│   ├── daemon.py             # Pool daemon
│   ├── servers.py            # Server management
│   ├── predictor.py          # Predictive warming
│   ├── query.py              # LSP query handling
│   └── config.py             # Configuration
├── servers/                  # Server definitions
│   ├── typescript.yaml
│   ├── python.yaml
│   ├── rust.yaml
│   └── go.yaml
├── completions/
│   └── lsp-pool.bash
└── tests/
    └── test_pool.py

================================================================================
                              MAIN CLI (lsp-pool)
================================================================================

```bash
#!/usr/bin/env bash
# lsp-pool - Pre-warmed Language Server Pool for Daedalos

set -euo pipefail

LSPPOOL_VERSION="1.0.0"
LSPPOOL_CONFIG="${XDG_CONFIG_HOME:-$HOME/.config}/daedalos/lsp-pool"
LSPPOOL_DATA="${XDG_DATA_HOME:-$HOME/.local/share}/daedalos/lsp-pool"
LSPPOOL_SOCKET="${LSPPOOL_SOCKET:-/run/daedalos/lsp-pool.sock}"

mkdir -p "$LSPPOOL_CONFIG" "$LSPPOOL_DATA"

cmd_start() {
    echo "Starting LSP Pool..."
    python3 -m lsppool.daemon start "$@"
}

cmd_stop() {
    python3 -m lsppool.daemon stop
}

cmd_status() {
    python3 -m lsppool.daemon status "$@"
}

cmd_warm() {
    local language="$1"
    local path="${2:-.}"
    python3 -m lsppool.servers warm --language "$language" --path "$path"
}

cmd_cool() {
    local language="$1"
    python3 -m lsppool.servers cool --language "$language"
}

cmd_query() {
    local command="$1"
    shift
    python3 -m lsppool.query "$command" "$@"
}

cmd_list() {
    python3 -m lsppool.servers list "$@"
}

cmd_predict() {
    python3 -m lsppool.predictor show
}

main() {
    case "${1:-help}" in
        start)      shift; cmd_start "$@" ;;
        stop)       shift; cmd_stop "$@" ;;
        status)     shift; cmd_status "$@" ;;
        warm)       shift; cmd_warm "$@" ;;
        cool)       shift; cmd_cool "$@" ;;
        query)      shift; cmd_query "$@" ;;
        list)       shift; cmd_list "$@" ;;
        config)     shift; cmd_config "$@" ;;
        logs)       shift; cmd_logs "$@" ;;
        predict)    shift; cmd_predict "$@" ;;
        version)    echo "lsp-pool $LSPPOOL_VERSION" ;;
        help|--help|-h) cmd_help ;;
        *)          echo "Unknown command: $1"; exit 1 ;;
    esac
}

main "$@"
```

================================================================================
                              DAEMON (daemon.py)
================================================================================

```python
"""LSP Pool Daemon - manages warm language servers."""

import asyncio
import json
from pathlib import Path
from dataclasses import dataclass
from typing import Optional
import psutil
import time


@dataclass
class ServerState:
    language: str
    project: Path
    process: asyncio.subprocess.Process
    pid: int
    memory_mb: float
    started_at: float
    last_query: float
    status: str  # "warm" | "initializing" | "hibernated"


class LSPPoolDaemon:
    """Daemon managing pool of language servers."""

    def __init__(self, config: dict, socket_path: Path):
        self.config = config
        self.socket_path = socket_path
        self.servers: dict[str, ServerState] = {}
        self.max_servers = config.get("max_servers", 5)
        self.memory_limit_mb = config.get("memory_limit_mb", 2048)

    async def start(self):
        """Start the pool daemon."""
        # Start predicted servers
        predictions = self._get_predictions()
        for pred in predictions[:self.max_servers]:
            await self.warm(pred["language"], Path(pred["project"]))

        # Listen for requests
        await self._listen()

    async def warm(self, language: str, project: Path, priority: str = "normal"):
        """Warm a server for a language/project."""
        key = f"{language}:{project}"

        if key in self.servers:
            return  # Already warm

        # Check resource limits
        if len(self.servers) >= self.max_servers:
            await self._evict_lowest_priority()

        if self._current_memory() + self._estimate_memory(language) > self.memory_limit_mb:
            await self._evict_for_memory(self._estimate_memory(language))

        # Start the server
        server_config = self._get_server_config(language)
        process = await asyncio.create_subprocess_exec(
            *server_config["command"].split(),
            stdin=asyncio.subprocess.PIPE,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
            cwd=project
        )

        self.servers[key] = ServerState(
            language=language,
            project=project,
            process=process,
            pid=process.pid,
            memory_mb=0,
            started_at=time.time(),
            last_query=time.time(),
            status="initializing"
        )

        # Initialize LSP connection
        await self._initialize_server(key)
        self.servers[key].status = "warm"

    async def cool(self, language: str, project: Optional[Path] = None):
        """Stop a server."""
        if project:
            key = f"{language}:{project}"
            if key in self.servers:
                await self._stop_server(key)
        else:
            # Cool all servers for this language
            keys_to_remove = [k for k in self.servers if k.startswith(f"{language}:")]
            for key in keys_to_remove:
                await self._stop_server(key)

    async def query(self, command: str, file: Path, line: int, col: int) -> dict:
        """Send LSP query to appropriate server."""
        language = self._detect_language(file)
        project = self._find_project_root(file)
        key = f"{language}:{project}"

        # Warm if not ready
        if key not in self.servers:
            await self.warm(language, project, priority="high")

        server = self.servers[key]
        server.last_query = time.time()

        # Send LSP request
        if command == "hover":
            return await self._request_hover(server, file, line, col)
        elif command == "definition":
            return await self._request_definition(server, file, line, col)
        elif command == "references":
            return await self._request_references(server, file, line, col)
        elif command == "completion":
            return await self._request_completion(server, file, line, col)
        elif command == "diagnostics":
            return await self._request_diagnostics(server, file)
        else:
            raise ValueError(f"Unknown command: {command}")

    async def _initialize_server(self, key: str):
        """Send LSP initialize request."""
        server = self.servers[key]

        init_request = {
            "jsonrpc": "2.0",
            "id": 1,
            "method": "initialize",
            "params": {
                "processId": None,
                "rootUri": f"file://{server.project}",
                "capabilities": {}
            }
        }

        await self._send_request(server, init_request)

        # Send initialized notification
        await self._send_notification(server, "initialized", {})

    async def _send_request(self, server: ServerState, request: dict) -> dict:
        """Send JSON-RPC request to server."""
        content = json.dumps(request)
        message = f"Content-Length: {len(content)}\r\n\r\n{content}"

        server.process.stdin.write(message.encode())
        await server.process.stdin.drain()

        # Read response
        header = await server.process.stdout.readline()
        content_length = int(header.decode().split(":")[1].strip())
        await server.process.stdout.readline()  # Empty line
        content = await server.process.stdout.read(content_length)

        return json.loads(content)

    async def _send_notification(self, server: ServerState, method: str, params: dict):
        """Send JSON-RPC notification (no response expected)."""
        notification = {
            "jsonrpc": "2.0",
            "method": method,
            "params": params
        }
        content = json.dumps(notification)
        message = f"Content-Length: {len(content)}\r\n\r\n{content}"

        server.process.stdin.write(message.encode())
        await server.process.stdin.drain()

    async def _request_hover(self, server: ServerState, file: Path, line: int, col: int) -> dict:
        """Request hover information."""
        request = {
            "jsonrpc": "2.0",
            "id": 2,
            "method": "textDocument/hover",
            "params": {
                "textDocument": {"uri": f"file://{file}"},
                "position": {"line": line - 1, "character": col - 1}
            }
        }
        return await self._send_request(server, request)

    async def _request_definition(self, server: ServerState, file: Path, line: int, col: int) -> dict:
        """Request go-to-definition."""
        request = {
            "jsonrpc": "2.0",
            "id": 2,
            "method": "textDocument/definition",
            "params": {
                "textDocument": {"uri": f"file://{file}"},
                "position": {"line": line - 1, "character": col - 1}
            }
        }
        return await self._send_request(server, request)

    async def _request_completion(self, server: ServerState, file: Path, line: int, col: int) -> dict:
        """Request completions."""
        request = {
            "jsonrpc": "2.0",
            "id": 2,
            "method": "textDocument/completion",
            "params": {
                "textDocument": {"uri": f"file://{file}"},
                "position": {"line": line - 1, "character": col - 1}
            }
        }
        return await self._send_request(server, request)

    async def _stop_server(self, key: str):
        """Stop a server."""
        server = self.servers[key]
        server.process.terminate()
        await server.process.wait()
        del self.servers[key]

    async def _evict_lowest_priority(self):
        """Evict the lowest priority server to make room."""
        # Sort by last_query (oldest first)
        sorted_servers = sorted(
            self.servers.items(),
            key=lambda x: x[1].last_query
        )
        if sorted_servers:
            await self._stop_server(sorted_servers[0][0])

    def _current_memory(self) -> float:
        """Get current total memory usage of pool."""
        total = 0
        for server in self.servers.values():
            try:
                process = psutil.Process(server.pid)
                server.memory_mb = process.memory_info().rss / 1024 / 1024
                total += server.memory_mb
            except psutil.NoSuchProcess:
                pass
        return total

    def _estimate_memory(self, language: str) -> float:
        """Estimate memory for a language server."""
        estimates = {
            "typescript": 400,
            "python": 300,
            "rust": 500,
            "go": 200,
            "java": 600
        }
        return estimates.get(language, 300)

    def _detect_language(self, file: Path) -> str:
        """Detect language from file extension."""
        ext_map = {
            ".ts": "typescript",
            ".tsx": "typescript",
            ".js": "typescript",
            ".jsx": "typescript",
            ".py": "python",
            ".rs": "rust",
            ".go": "go",
            ".java": "java",
            ".c": "c",
            ".cpp": "cpp",
            ".h": "c"
        }
        return ext_map.get(file.suffix, "unknown")

    def _find_project_root(self, file: Path) -> Path:
        """Find project root (directory with package.json, Cargo.toml, etc.)."""
        markers = ["package.json", "Cargo.toml", "pyproject.toml", "go.mod", ".git"]
        current = file.parent

        while current != current.parent:
            for marker in markers:
                if (current / marker).exists():
                    return current
            current = current.parent

        return file.parent

    def _get_server_config(self, language: str) -> dict:
        """Get server configuration for language."""
        servers = {
            "typescript": {"command": "typescript-language-server --stdio"},
            "python": {"command": "pyright-langserver --stdio"},
            "rust": {"command": "rust-analyzer"},
            "go": {"command": "gopls serve"},
            "java": {"command": "jdtls"}
        }
        return servers.get(language, {})

    def _get_predictions(self) -> list[dict]:
        """Get predicted server needs."""
        # Simple implementation: check recent directories
        # Full implementation would use the predictor module
        return []

    async def _listen(self):
        """Listen for requests on Unix socket."""
        server = await asyncio.start_unix_server(
            self._handle_client,
            path=str(self.socket_path)
        )
        async with server:
            await server.serve_forever()

    async def _handle_client(self, reader, writer):
        """Handle incoming client request."""
        try:
            data = await reader.read(65536)
            request = json.loads(data.decode())

            if request["type"] == "query":
                result = await self.query(
                    request["command"],
                    Path(request["file"]),
                    request["line"],
                    request["col"]
                )
                response = {"success": True, "result": result}
            elif request["type"] == "warm":
                await self.warm(request["language"], Path(request["project"]))
                response = {"success": True}
            elif request["type"] == "status":
                response = {
                    "success": True,
                    "servers": [
                        {
                            "language": s.language,
                            "project": str(s.project),
                            "memory_mb": s.memory_mb,
                            "status": s.status
                        }
                        for s in self.servers.values()
                    ]
                }
            else:
                response = {"success": False, "error": "Unknown request"}

            writer.write(json.dumps(response).encode())
            await writer.drain()
        except Exception as e:
            response = {"success": False, "error": str(e)}
            writer.write(json.dumps(response).encode())
            await writer.drain()
        finally:
            writer.close()
```

================================================================================
                           PREDICTOR (predictor.py)
================================================================================

```python
"""Predictive warming - anticipate which servers will be needed."""

import sqlite3
from pathlib import Path
from datetime import datetime, timedelta
from collections import defaultdict


class Predictor:
    """Predict which language servers will be needed."""

    def __init__(self, db_path: Path):
        self.db_path = db_path
        self._init_db()

    def _init_db(self):
        """Initialize prediction database."""
        conn = sqlite3.connect(self.db_path)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS activity (
                id INTEGER PRIMARY KEY,
                language TEXT,
                project TEXT,
                timestamp DATETIME,
                query_count INTEGER DEFAULT 1
            )
        """)
        conn.commit()
        conn.close()

    def record_activity(self, language: str, project: Path):
        """Record that a server was used."""
        conn = sqlite3.connect(self.db_path)
        conn.execute(
            "INSERT INTO activity (language, project, timestamp) VALUES (?, ?, ?)",
            (language, str(project), datetime.now())
        )
        conn.commit()
        conn.close()

    def predict(self, n: int = 5) -> list[dict]:
        """Predict top N servers to warm."""
        conn = sqlite3.connect(self.db_path)

        # Get recent activity (last 24 hours)
        cutoff = datetime.now() - timedelta(hours=24)
        rows = conn.execute(
            """
            SELECT language, project, COUNT(*) as count
            FROM activity
            WHERE timestamp > ?
            GROUP BY language, project
            ORDER BY count DESC
            LIMIT ?
            """,
            (cutoff, n)
        ).fetchall()

        predictions = []
        for row in rows:
            predictions.append({
                "language": row[0],
                "project": row[1],
                "confidence": min(0.95, row[2] / 10)  # Scale confidence
            })

        conn.close()
        return predictions
```

================================================================================
                           SUCCESS CRITERIA
================================================================================

The lsp-pool tool is complete when:

1. DAEMON
   [ ] Starts and manages server pool
   [ ] Enforces memory limits
   [ ] Evicts idle servers appropriately

2. SERVER MANAGEMENT
   [ ] warm starts server for language/project
   [ ] cool stops servers
   [ ] status shows running servers

3. QUERIES
   [ ] hover works
   [ ] definition works
   [ ] references works
   [ ] completion works
   [ ] diagnostics works

4. PREDICTION
   [ ] Records usage patterns
   [ ] Pre-warms likely-needed servers

================================================================================
