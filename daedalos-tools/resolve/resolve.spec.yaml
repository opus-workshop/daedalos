name: resolve
version: 1.0
created: 2025-01-11

intent: |
  Agents stop and ask too many questions. This kills flow and externalizes
  work the agent should do itself.

  Resolve exists because uncertainty should be RESOLVED, not EXTERNALIZED.
  When an agent is uncertain, it should work toward confidence through
  context gathering and reasoning - not by asking the user to decide.

  The key insight: there are two types of uncertainty:

  1. INTENT uncertainty - "What problem are we actually solving?"
     → This warrants asking the user (targeted questions)

  2. IMPLEMENTATION uncertainty - "How should we solve it?"
     → This should be resolved through context, never asked

  Resolve handles both phases. It loops on intent until clear, then
  gathers context and decides on implementation without asking.

  Human equivalent: A senior developer who asks "what are we building?"
  but never asks "should I use a for-loop or map?" - they figure it out.

constraints:
  - Intent questions must be targeted (binary/small set, not open-ended)
  - Implementation questions are NEVER asked - always resolved
  - Uses existing Daedalos tools (spec, codex, project, web search)
  - Logs decisions to DECISIONS.md for future reference
  - Fast enough to not disrupt flow (< 5s for most resolutions)
  - Works without network (graceful degradation if web search unavailable)

interface:
  commands:
    resolve:
      args: "<question or task description>"
      returns: |
        Intent: Clarified problem statement
        Context: What was gathered
        Decision: Recommended approach with reasoning
        Confidence: high/medium/low
      example: "resolve 'how should timezone be handled?'"

  phases:
    intent:
      purpose: "Ensure we're solving the right problem"
      behavior: |
        1. Analyze surface question vs root problem
        2. If intent unclear, ask targeted questions (loop until clear)
        3. Use AskUserQuestion to batch multiple unknowns
        4. Exit when intent is clear enough for implementation
      outputs:
        - surface: "What was literally asked"
        - root: "The actual problem to solve"
        - constraints: "Known requirements and preferences"

    confidence:
      purpose: "Build confidence in implementation decision"
      behavior: |
        1. List questions that would otherwise be asked
        2. For each, gather context to answer it:
           - spec query (prior decisions, principles)
           - codex search (existing patterns)
           - project info (conventions)
           - error-db (known solutions)
           - web search (best practices) - if needed
        3. Synthesize into recommendation
        4. Log decision to DECISIONS.md
      outputs:
        - context: "What was found"
        - decision: "Recommended approach"
        - reasoning: "Why this decision"
        - confidence: "high/medium/low"

  confidence_levels:
    high: "Consistent signals from multiple sources - proceed silently"
    medium: "Some gaps but reasonable inference - proceed, state assumption"
    low: "Conflicting signals or missing critical info - genuine ambiguity, ask"

  integration:
    reads_from:
      - "spec query - prior decisions and principles"
      - "codex search - existing codebase patterns"
      - "project info - conventions and structure"
      - "error-db - known problems and solutions"
      - "web search - best practices and standards"
      - ".claude/DECISIONS.md - past decisions in this project"

    writes_to:
      - ".claude/DECISIONS.md - logs new decisions for future reference"

examples:
  - scenario: "Ambiguous user request"
    input: "resolve 'user asked about hooks to reduce asking behavior'"
    intent_phase: |
      Surface: "Hooks to reduce asking"
      Root unclear - what's the actual goal?

      → Ask: "Is the goal to (A) suppress questions, or (B) make agents
              genuinely more confident so they don't need to ask?"
      → User: "B - genuine confidence"

      Root: "How does Daedalos systemically make agents more confident?"
    confidence_phase: |
      Questions I would ask:
        - "What tools already exist for context gathering?"
        - "Should this be a tool, skill, or behavioral rule?"
        - "How should it integrate with existing primitives?"

      Gathering context:
        - spec query: loop.spec.yaml, gates.spec.yaml
        - codex search: existing uncertainty handling
        - project info: Daedalos architecture

      Decision: Build 'resolve' tool that orchestrates existing primitives
      Reasoning: Tools exist (spec, codex, project) but no orchestration
      Confidence: High
    result: "Proceeds to design resolve tool without further questions"

  - scenario: "Technical decision with clear intent"
    input: "resolve 'should timezone be user-level or slot-level?'"
    intent_phase: |
      Surface: Timezone storage granularity
      Root: Same (technical question with clear intent)

      No questions needed - intent is clear
    confidence_phase: |
      Questions I would ask:
        - "What's the existing pattern for similar settings?"
        - "What do specs say about user preferences?"
        - "What's industry standard?"

      Gathering context:
        - codex search "user settings locale" → user-level pattern
        - spec query "user preferences" → "user-scoped by default"
        - web search → user-level with display override

      Decision: User-level timezone
      Reasoning: Matches existing locale pattern, aligns with spec
      Confidence: High
    result: "Proceeds with user-level timezone, logs to DECISIONS.md"

  - scenario: "Genuine ambiguity requiring user input"
    input: "resolve 'which auth provider should we use?'"
    intent_phase: |
      Clear: Need to choose auth provider
    confidence_phase: |
      Gathering context:
        - spec query: No prior auth decisions
        - codex search: No existing auth code
        - project info: New project, no patterns
        - web search: Multiple valid options (Auth0, Clerk, Supabase)

      Signals conflict:
        - Auth0: Most mature
        - Clerk: Best DX
        - Supabase: Already using for DB

      Decision: NONE - genuine ambiguity
      Confidence: Low

      → Ask: "Auth provider options: (A) Auth0 - most mature,
              (B) Clerk - best DX, (C) Supabase - already in stack.
              This is a significant architectural decision."
    result: "Asks because genuinely ambiguous and high-stakes"

  - scenario: "Multiple unclear dimensions"
    input: "resolve 'build a scheduling feature'"
    intent_phase: |
      Surface: Scheduling feature
      Multiple unknowns: audience, priority, scope

      → AskUserQuestion (batched):
          Audience?  ○ Internal  ○ Customer-facing
          Priority?  ○ Speed     ○ Polish
          Scope?     ○ MVP       ○ Full feature

      → User answers all three in one interaction

      Root: Customer-facing MVP, optimize for speed
    confidence_phase: |
      (proceeds with all implementation decisions internally)
    result: "One batched question, then no more questions"

decisions:
  - choice: "Intent questions allowed, implementation questions forbidden"
    why: |
      Intent uncertainty wastes significant work if wrong - building the
      wrong thing entirely. Worth asking upfront.

      Implementation uncertainty is resolvable through context - specs,
      patterns, research all exist. No reason to ask.

      This creates a clear rule: "Am I asking about WHAT or HOW?"
      WHAT = can ask. HOW = must resolve.
    alternatives:
      - option: "Never ask any questions"
        rejected_because: "Building wrong thing wastes more time than asking"
      - option: "Ask about everything"
        rejected_because: "Externalizes work agent should do, kills flow"

  - choice: "Loop on intent until clear"
    why: |
      Sometimes one question isn't enough. Intent might have multiple
      unclear dimensions, or first answer reveals new questions.

      Loop ensures we don't proceed until genuinely clear.
      But each iteration must add information (not repeat).
    alternatives:
      - option: "Exactly one intent question allowed"
        rejected_because: "Arbitrary limit, sometimes need more"
      - option: "Unlimited questions"
        rejected_because: "Could become question spam - need constraint"

  - choice: "Batch questions with AskUserQuestion when possible"
    why: |
      Multiple independent unknowns should be batched into one interaction.
      User answers all at once, more efficient than sequential.

      Only go sequential when answers depend on each other.
    alternatives:
      - option: "Always sequential"
        rejected_because: "Wastes user time on independent questions"
      - option: "Always batch everything"
        rejected_because: "Some questions depend on prior answers"

  - choice: "Log decisions to DECISIONS.md"
    why: |
      Agents lose memory between sessions. Past decisions become
      context for future resolve calls.

      "Last time we faced X, we chose Y because Z."

      Builds institutional memory in the project.
    alternatives:
      - option: "Don't log decisions"
        rejected_because: "Same decisions re-debated every session"
      - option: "Log to database"
        rejected_because: "Markdown is human-readable, versionable, portable"

  - choice: "Use existing Daedalos primitives"
    why: |
      spec, codex, project, error-db already exist and are good.
      Resolve orchestrates them, doesn't replace them.

      This keeps resolve focused on the PROCESS, not reimplementing
      context gathering.
    alternatives:
      - option: "Build custom context gathering"
        rejected_because: "Duplicates existing tools, maintenance burden"

  - choice: "Answer your own questions as internal framing"
    why: |
      During confidence phase, explicitly list "questions I would ask"
      then answer each through context gathering.

      Makes the process transparent and debuggable.
      Helps catch the moment where agent would have asked.
    alternatives:
      - option: "Implicit context gathering"
        rejected_because: "Less clear what's happening, harder to debug"

anti_patterns:
  - pattern: "Asking implementation questions"
    why_bad: |
      "Should I use approach A or B?" is resolvable through context.
      Specs, codebase patterns, research can answer this.

      Asking externalizes work the agent should do.

  - pattern: "Open-ended intent questions"
    why_bad: |
      "What do you want?" is lazy. It doesn't show understanding.

      Good: "Is the goal X (because A) or Y (because B)?"
      Bad: "What are you trying to do?"

      Questions should demonstrate thought, not absence of it.

  - pattern: "Question spam"
    why_bad: |
      Asking 5 questions in a row kills flow.

      Batch independent questions with AskUserQuestion.
      Only go sequential when truly dependent.

  - pattern: "Proceeding with unclear intent"
    why_bad: |
      "I'll just assume X" when intent is genuinely unclear
      leads to building the wrong thing.

      Intent questions are allowed precisely to prevent this.

  - pattern: "Ignoring DECISIONS.md"
    why_bad: |
      Past decisions are context. "We chose X before for reason Y"
      informs current decisions.

      Always check DECISIONS.md during confidence phase.

  - pattern: "Overriding low confidence"
    why_bad: |
      If resolve returns low confidence, it's genuine ambiguity.
      Don't proceed anyway - ask the user.

      Low confidence should be rare (conflicting signals, missing
      critical info). When it happens, it's real.

connects_to:
  - component: spec
    relationship: |
      Resolve queries specs for prior decisions and principles.
      Rich specs = more confident decisions.

      spec query is primary source during confidence phase.

  - component: codex
    relationship: |
      Resolve uses codex search to find existing patterns.
      "How does the codebase already handle this?"

      Patterns inform implementation decisions.

  - component: project
    relationship: |
      Resolve uses project info for conventions and structure.
      "What are the established patterns here?"

  - component: error-db
    relationship: |
      When resolving error-related questions, check error-db first.
      "Has this been solved before?"

  - component: loop
    relationship: |
      Resolve can be called at start of loop iterations.
      "Before attempting fix, resolve approach."

      But resolve is not itself a loop primitive - it's invoked,
      returns, and agent proceeds.

  - component: journal
    relationship: |
      Resolve decisions can be logged to journal for visibility.
      "Agent resolved X, decided Y, reasoning Z."

metrics:
  success_criteria:
    - "Implementation questions drop to near zero"
    - "Intent questions are targeted and productive"
    - "Agents proceed confidently after resolve"
    - "DECISIONS.md captures useful institutional memory"
    - "Resolve completes in < 5s for typical questions"
    - "Low confidence is rare (< 5% of resolutions)"

  failure_indicators:
    - "Agents still ask implementation questions"
    - "Intent questions are vague or open-ended"
    - "Resolve takes too long, disrupts flow"
    - "Low confidence returned too often (tool not helping)"
    - "DECISIONS.md not consulted or written to"
    - "Users report resolve makes wrong decisions frequently"
