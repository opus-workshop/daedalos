name: gates
version: 1.0
created: 2025-01-11

intent: |
  Trust is earned, not given. Control how much autonomy AI gets.

  Gates exists because AI autonomy is a spectrum, not binary. Some users
  want agents to work freely. Others want approval for every file change.
  Both are valid. Gates makes this configurable.

  The deeper insight: supervision isn't about distrust, it's about risk
  management. Low-risk actions (read files) can be autonomous. High-risk
  actions (delete files, push code) might need approval. Gates encodes
  this nuance.

  Human equivalent: A junior developer who needs sign-off on certain changes.
  Gates is that policy, applied to AI agents.

constraints:
  - Fast check: Gate check must complete in < 10ms (on hot path)
  - Offline: No network calls, all local config
  - Layered config: Global defaults → user config → project override
  - Project can only restrict, not loosen (defense in depth)
  - Audit trail: All gate checks logged to history
  - Graceful degradation: If config missing, use safe defaults

interface:
  commands:
    check:
      args: "<gate> [context-json] [source]"
      returns: "allowed/denied with reason, exit 0 or 1"
      example: "gates check git_push"

    level:
      args: "[LEVEL]"
      returns: "Gets or sets supervision level"
      example: "gates level supervised"

    set:
      args: "<gate> <action>"
      returns: "Configures a specific gate"
      example: "gates set git_push approve"

    config:
      args: "[--json]"
      returns: "Shows current configuration"
      example: "gates config"

    history:
      args: "[--gate G] [--days N] [--limit N]"
      returns: "Recent gate check history"
      example: "gates history --gate git_push"

    init:
      args: ""
      returns: "Creates config file with defaults"
      example: "gates init"

  levels:
    autonomous: "AI runs freely, only catastrophic actions gated"
    supervised: "AI runs, human gets notifications for key actions"
    collaborative: "AI proposes, human approves major changes"
    assisted: "Human drives, AI suggests and helps"
    manual: "AI only responds to direct commands"

  actions:
    allow: "Proceed without asking"
    notify: "Proceed but notify human"
    approve: "Block until human approves"
    deny: "Always deny this action"

  gates:
    file_delete: "Deleting files"
    file_create: "Creating new files"
    file_modify: "Modifying existing files"
    git_commit: "Making git commits"
    git_push: "Pushing to remote"
    git_force_push: "Force pushing (dangerous)"
    loop_start: "Starting iteration loops"
    agent_spawn: "Spawning new agents"
    shell_command: "Running shell commands"
    sensitive_file: "Modifying secrets, env, keys"

  exit_codes:
    0: "Action allowed"
    1: "Action denied"
    2: "Configuration error"

examples:
  - scenario: "Setting supervision level"
    context: "User wants AI to work but get notified of significant actions"
    action: "gates level supervised"
    result: "Level set, AI proceeds but human sees notifications"
    why_it_matters: |
      One command sets overall policy. Don't need to configure each gate.
      Level sets sensible defaults, fine-tune with 'gates set' if needed.

  - scenario: "Requiring approval for git push"
    context: "Comfortable with local changes, cautious about remote"
    action: "gates set git_push approve"
    result: "AI can code freely, but push requires human approval"
    why_it_matters: |
      Targeted restriction. AI does 90% autonomously, human controls
      the 10% that matters (deployment, sharing).

  - scenario: "Hook checking before file edit"
    context: "Claude Code hook runs gates check before Edit tool"
    action: "gates check file_modify '{\"file\": \".env\"}'"
    result: "Denied for sensitive file, agent must ask human"
    why_it_matters: |
      Integration point. Hooks call gates, gates enforce policy.
      Human doesn't need to watch every action.

  - scenario: "Reviewing what happened"
    context: "Want to see what gates were checked today"
    action: "gates history --days 1"
    result: "Timeline of all gate checks with results"
    why_it_matters: |
      Audit trail. Can review AI activity after the fact.
      Did it try to do something it shouldn't?

decisions:
  - choice: "Levels set gate defaults, not hard overrides"
    why: |
      Changing level resets gates to level defaults.
      This keeps behavior predictable.

      User can then customize: "gates set git_push deny" to be stricter.

      The level is the baseline, set commands are customization.
    alternatives:
      - option: "Levels as strict presets (can't modify)"
        rejected_because: "Too rigid, users need fine-tuning"
      - option: "No levels, only individual gates"
        rejected_because: "Too complex for common cases, levels provide shortcuts"

  - choice: "Project config can only restrict, never loosen"
    why: |
      Defense in depth. If user config says "approve git_push",
      project config cannot override to "allow".

      This prevents malicious repos from loosening security.

      Project config applies: max(user_strictness, project_strictness)
    alternatives:
      - option: "Project config fully overrides"
        rejected_because: "Security risk - repo could bypass user controls"
      - option: "Ignore project config entirely"
        rejected_because: "Legitimate use case for projects with higher sensitivity"

  - choice: "Sensitive path detection via patterns"
    why: |
      Some files are always sensitive: .env, secrets/, *.key
      These get automatic "approve" or "deny" regardless of general config.

      Patterns configured in autonomy.sensitive_paths.

      Prevents accidental exposure of secrets.
    alternatives:
      - option: "Manual sensitive file list"
        rejected_because: "Easy to forget, patterns cover more cases"
      - option: "Content-based detection"
        rejected_because: "Requires reading file, slow, complex"

  - choice: "History stored in SQLite"
    why: |
      Gate checks are frequent, need fast writes.
      SQLite handles concurrent writes safely.

      History enables: audit, debugging, pattern detection.

      Stored at: ~/.local/share/daedalos/gates/history.db
    alternatives:
      - option: "Log files"
        rejected_because: "Hard to query, rotation complexity"
      - option: "JSON append"
        rejected_because: "Concurrent write issues, grows unbounded"

anti_patterns:
  - pattern: "Setting everything to 'allow' for convenience"
    why_bad: |
      Defeats the purpose. Might as well not use gates.

      If you want autonomy, use 'autonomous' level which has sensible
      defaults for truly dangerous actions (force push = deny).

  - pattern: "Setting everything to 'approve' (over-supervision)"
    why_bad: |
      Death by a thousand approvals. Agent can't work, you're
      constantly interrupted.

      Use 'collaborative' level which balances oversight and flow.

  - pattern: "Ignoring denied actions in code"
    why_bad: |
      Gates returns exit code 1 on deny. If your code ignores this
      and proceeds anyway, gates is useless.

      Hooks should check return code and abort if denied.

  - pattern: "Not reviewing gate history periodically"
    why_bad: |
      History exists for audit. If you never review it, you miss:
      - Patterns of denied actions (agent trying to do something?)
      - Actions that should be gated but aren't
      - Opportunities to adjust levels

connects_to:
  - component: observe
    relationship: |
      Observe shows pending gate approvals.
      "Gate pending: git_push awaiting approval in terminal 2"

      This makes blocked agents visible.

  - component: journal
    relationship: |
      Gate checks logged to journal for narrative reconstruction.
      "What happened?" includes gate checks and their outcomes.

  - component: loop
    relationship: |
      Loop respects gates before each iteration.
      If 'loop_start' requires approval, loop waits.

      Gate context includes: loop_id, task, iteration_count

  - component: agent
    relationship: |
      Agent spawn can be gated.
      In 'collaborative' mode, spawning new agents requires approval.

      Prevents runaway agent multiplication.

  - component: undo
    relationship: |
      Gates can require checkpoint before destructive actions.
      file_delete → auto-checkpoint first, then allow.

      Safety belt: even if delete allowed, undo exists.

metrics:
  success_criteria:
    - "Gate check < 10ms (fast enough for hot path)"
    - "Users find the right supervision level for their comfort"
    - "Denied actions don't surprise users (config matches expectation)"
    - "History enables effective audit and debugging"
    - "Project overrides work correctly (only restrict)"

  failure_indicators:
    - "Gate checks slow down operations noticeably"
    - "Users disable gates entirely (too annoying)"
    - "Agents bypass gates (integration failures)"
    - "History grows unbounded (no cleanup)"
    - "Project config loosens security (bug!)"
