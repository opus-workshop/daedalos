name: codex
version: 1.0
created: 2025-01-11

intent: |
  Find code by meaning, not just keywords.

  Codex exists because grep is not enough. "Where is authentication handled?"
  can't be answered by searching for the string "authentication" - the code
  might use "login", "auth", "session", or none of these words.

  The deeper insight: AI agents hallucinate when they don't know the codebase.
  They invent functions that don't exist, use wrong patterns, repeat mistakes.
  Codex grounds agents in reality - "before you write auth code, search for
  existing auth patterns with: codex search 'authentication'"

  This is pre-computed codebase intelligence. Instead of reading hundreds of
  files hoping to understand the patterns, ask a question and get answers.

  Human equivalent: "Hey, you know this codebase - where would I find X?"
  Codex is that experienced teammate who knows where everything is.

constraints:
  - Works without API keys: TF-IDF fallback when Ollama unavailable
  - Index < 30 seconds for typical project (< 10k files)
  - Search < 500ms after indexing
  - Respects .gitignore: Never index generated/vendored code
  - Minimal storage: ~10-50MB per 1000 files indexed
  - No network required: Ollama runs locally, TF-IDF has no dependencies
  - Automatic reindex on stale detection (modified files since last index)

interface:
  commands:
    search:
      args: "<query> [-n limit] [-f file_pattern] [-t type] [-c show_content]"
      returns: "Ranked list of relevant code chunks with file:line locations"
      example: "codex search 'where is authentication handled?'"

    index:
      args: "[--force]"
      returns: "Builds or updates the search index"
      example: "codex index"

    status:
      args: ""
      returns: "Index statistics (files, chunks, backend, freshness)"
      example: "codex status"

    clear:
      args: ""
      returns: "Deletes the index"
      example: "codex clear"

    similar:
      args: "<file> <line> [-n limit]"
      returns: "Code similar to the specified location"
      example: "codex similar src/auth.py 42"

    explain:
      args: "<file> <query> [-n limit]"
      returns: "Search within a specific file"
      example: "codex explain src/auth.py 'how does login work?'"

  options:
    project: "-p PATH: Project path (default: auto-detect from cwd)"
    limit: "-n N: Number of results (default: 5)"
    file: "-f PATTERN: Filter results by file path"
    type: "-t TYPE: Filter by chunk type (function, class, module)"
    content: "-c: Show code content in results"
    reindex: "--reindex: Force fresh index before search"

  exit_codes:
    0: "Success"
    1: "No results found or search error"
    2: "Index not found (run codex index)"
    3: "Configuration or backend error"

examples:
  - scenario: "Agent starting a task"
    context: "Loop starting 'add rate limiting to API'"
    action: "codex search 'rate limiting' 'throttling' 'API middleware'"
    result: "Shows existing rate limit code, middleware patterns used"
    why_it_matters: |
      Agent now knows: rate limiting exists, where it lives, what pattern
      to follow. No hallucination. No reinventing existing code.

  - scenario: "Debugging unfamiliar code"
    context: "Error in auth module, developer doesn't know the codebase"
    action: "codex search 'authentication flow' 'login error handling'"
    result: "Points to relevant files, shows error handling patterns"
    why_it_matters: |
      Onboarding accelerator. New developer (human or AI) learns codebase
      patterns quickly by asking questions.

  - scenario: "Finding similar code"
    context: "Found a pattern you like, want to see other usages"
    action: "codex similar src/auth/login.py 45"
    result: "Shows code chunks with similar embedding (similar meaning)"
    why_it_matters: |
      Copy-paste driven development, but smart. Find patterns that worked
      and apply them elsewhere.

  - scenario: "Understanding a specific file"
    context: "Complex file, need to understand specific aspect"
    action: "codex explain src/payment.py 'how is refund calculated?'"
    result: "Points to relevant functions within that file"
    why_it_matters: |
      Scoped search. Big file, specific question. Don't read everything,
      find the relevant part.

  - scenario: "Preventing duplication"
    context: "About to implement feature X"
    action: "codex search 'feature X' before writing code"
    result: "Discovers existing implementation (or confirms none exists)"
    why_it_matters: |
      Stop reinventing the wheel. Check if it exists before building.
      AI agents are especially prone to reimplementing existing code.

decisions:
  - choice: "Chunk by semantic units (functions, classes), not fixed size"
    why: |
      Fixed-size chunking (500 tokens) breaks code at arbitrary points.
      A function split in two chunks loses meaning.

      Semantic chunking respects code structure:
      - Functions are single chunks
      - Classes with their docstrings
      - Modules (imports + top-level)

      This means search results are meaningful units, not fragments.
    alternatives:
      - option: "Fixed-size token chunking"
        rejected_because: "Loses semantic boundaries, results are fragments"
      - option: "Whole-file embeddings"
        rejected_because: "Too coarse, can't find specific functions"
      - option: "Line-by-line"
        rejected_because: "Too fine, loses context, slow"

  - choice: "Ollama primary, TF-IDF fallback"
    why: |
      Ollama gives real semantic understanding:
      - "auth" matches "authentication", "login", "session"
      - Understands code patterns, not just keywords

      But Ollama requires installation. TF-IDF works anywhere:
      - No dependencies
      - Fast
      - Good enough for keyword-heavy queries

      Graceful degradation: best experience when Ollama available,
      still useful without it.
    alternatives:
      - option: "Require Ollama"
        rejected_because: "Breaks FOSS/offline constraint, setup friction"
      - option: "Use OpenAI/Claude embeddings"
        rejected_because: "Requires API key, network, costs money"
      - option: "TF-IDF only"
        rejected_because: "Missing the semantic magic that makes it powerful"

  - choice: "nomic-embed-text model"
    why: |
      Optimized for code understanding:
      - 768 dimensions (good quality, reasonable size)
      - Trained on code + natural language
      - Fast on CPU

      Runs on Ollama, so fully local and private.
    alternatives:
      - option: "mxbai-embed-large"
        rejected_because: "1024 dims, larger storage, slower"
      - option: "OpenAI ada-002"
        rejected_because: "Requires API key, network, costs"
      - option: "Custom fine-tuned model"
        rejected_because: "Maintenance burden, marginal gains"

  - choice: "SQLite for index storage"
    why: |
      Perfect fit:
      - Single file, portable
      - Fast queries for similarity search (with FTS5)
      - Embeddings stored as blobs
      - Atomic updates (no corruption)

      Storage location: ~/.local/share/daedalos/codex/{project_hash}/
    alternatives:
      - option: "Vector database (Pinecone, Milvus)"
        rejected_because: "External dependency, overkill for single-machine"
      - option: "Flat files (JSON)"
        rejected_because: "Slow search, no indexing"
      - option: "In-memory only"
        rejected_because: "Loses index on restart, slow reindex every time"

  - choice: "Auto-detect project root from markers"
    why: |
      Search for: .git, package.json, Cargo.toml, pyproject.toml, go.mod

      This finds the natural project boundary. Index the whole project,
      not just the current directory.

      Explicit -p flag available for override.
    alternatives:
      - option: "Always use current directory"
        rejected_because: "Misses project context when in subdirectory"
      - option: "Require explicit path"
        rejected_because: "Friction, most common case is 'this project'"

anti_patterns:
  - pattern: "Searching without indexing first"
    why_bad: |
      "codex search 'foo'" on unindexed project auto-indexes, which is slow.
      Run "codex index" first for instant searches.

      (We auto-index as fallback but it's not ideal UX.)

  - pattern: "Using codex for exact string search"
    why_bad: |
      "codex search 'getUserById'" will work but grep is faster.
      Codex shines for semantic queries: "where is user lookup?"

      Use the right tool: grep for exact, codex for semantic.

  - pattern: "Ignoring file type filters"
    why_bad: |
      "codex search 'database'" might return results from tests, docs, etc.
      Use "-f src/" to scope to source code.

      File filters make results more relevant.

  - pattern: "Not re-indexing after major changes"
    why_bad: |
      Big refactor → index is stale → search misses new code.
      Run "codex index --force" after significant changes.

      (Auto-reindex on stale detection helps but explicit is better.)

  - pattern: "Over-relying on TF-IDF fallback"
    why_bad: |
      TF-IDF is keyword matching. "authentication" won't find "login".
      Install Ollama for proper semantic search:
        ollama pull nomic-embed-text

connects_to:
  - component: loop
    relationship: |
      Before first loop iteration, inject codex context:
        codex search "{task description}" → add to prompt

      Agent starts grounded in relevant existing code, not guessing.

  - component: spec
    relationship: |
      Codex indexes specs alongside code:
        codex search "authentication intent"
        → finds auth.spec.yaml intent section

      Specs are searchable context.

  - component: project
    relationship: |
      Project tool provides codebase structure.
      Codex provides semantic search within that structure.

      project info → "what's in this codebase?"
      codex search → "where is X in this codebase?"

  - component: agent
    relationship: |
      Explorer template uses codex heavily:
        "codex search {topic}" to understand codebase

      Before any agent writes code, codex search first.

  - component: error-db
    relationship: |
      When error-db has no match, codex can help:
        codex search "error handling for {error type}"

      Find how similar errors are handled in this codebase.

metrics:
  success_criteria:
    - "Relevant result in top 3 for 80%+ of natural language queries"
    - "Index builds in < 30s for projects with < 10k files"
    - "Search returns in < 500ms"
    - "TF-IDF fallback usable (> 50% relevant results)"
    - "Agents use codex before writing code (observable behavior)"

  failure_indicators:
    - "Users use grep instead of codex (codex too slow or irrelevant)"
    - "Index grows beyond expected size (chunking too fine)"
    - "Ollama not installed (degraded experience common)"
    - "Agents ignore codex results (not useful enough)"
    - "Stale index causes wrong results (reindex not triggered)"
