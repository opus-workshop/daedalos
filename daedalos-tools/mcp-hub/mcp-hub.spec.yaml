name: mcp-hub
version: 1.0
created: 2025-01-11

intent: |
  MCP servers are a fragmentation nightmare waiting to happen.

  Every AI agent has its own MCP configuration. Every project duplicates server
  setup. Every developer re-discovers the same "how do I connect to GitHub?"
  problem. This fragmentation taxes cognitive load and creates inconsistency.

  MCP-Hub exists to collapse this complexity into a single point of management.
  One hub that knows all your servers, handles authentication once, and routes
  requests transparently. The agent doesn't need to know which server provides
  "read_file" - it just asks, and the hub delivers.

  The deeper philosophy: infrastructure should be invisible. A well-run MCP-Hub
  means developers never think about MCP servers at all. They think about tools.
  "I need to query GitHub" not "I need to configure and start the GitHub MCP
  server with the right authentication and ensure it's running."

  This is the difference between configuration and capability. MCP-Hub converts
  configuration burden into instant capability.

constraints:
  - FOSS-first: Official MCP servers prioritized, but any server works
  - Agent-agnostic: Works with Claude, OpenCode, Aider, Cursor, any MCP client
  - No vendor lock-in: API keys optional, local-only mode fully functional
  - Single source of truth: One config, not per-project duplication
  - Graceful degradation: Missing servers logged, not fatal
  - Fast routing: Tool lookup must be O(1), not search-per-request
  - Resource-aware: Won't spawn unlimited servers, respects system limits
  - Project overrides: Global config + per-project exceptions

interface:
  commands:
    start:
      args: "[--port <port>] [--socket <path>] [--config <path>]"
      returns: "Starts hub daemon, manages server pool"
      example: "mcp-hub start --port 7776"

    stop:
      args: ""
      returns: "Gracefully stops hub and all managed servers"
      example: "mcp-hub stop"

    status:
      args: "[--json]"
      returns: "Hub health, running servers, resource usage"
      example: "mcp-hub status"

    list:
      args: "[--category <cat>] [--capability <cap>] [--json]"
      returns: "All registered servers with status"
      example: "mcp-hub list --category databases"

    search:
      args: "<query>"
      returns: "Servers matching name, tool, or description"
      example: "mcp-hub search 'file read'"

    install:
      args: "<server> [--global | --project]"
      returns: "Installs server from registry, npm, GitHub, or local path"
      example: "mcp-hub install github:anthropics/mcp-server-github"

    tools:
      args: "[server] [--json]"
      returns: "Available tools across all or specific server"
      example: "mcp-hub tools github"

    call:
      args: "<tool> [args...] [--server <name>] [--json-args <json>]"
      returns: "Direct tool invocation from command line"
      example: "mcp-hub call read_file --path /etc/hostname"

    warm:
      args: "<servers...>"
      returns: "Pre-starts specified servers for fast response"
      example: "mcp-hub warm filesystem github postgres"

    config:
      args: "<server> [--set KEY=VALUE]"
      returns: "View or modify server configuration"
      example: "mcp-hub config postgres --set host=localhost"

    logs:
      args: "[server] [--follow] [--lines <n>]"
      returns: "Server logs for debugging"
      example: "mcp-hub logs github -f"

    restart:
      args: "<server>"
      returns: "Restart a specific server"
      example: "mcp-hub restart postgres"

  exit_codes:
    0: "Success"
    1: "General error"
    2: "Server not found"
    3: "Tool not found"
    4: "Authentication required"
    5: "Server failed to start"
    6: "Hub not running"

examples:
  - scenario: "Agent requests a tool"
    context: "AI agent needs to read a file, doesn't know which server provides it"
    action: "Agent sends MCP request for 'read_file' to hub"
    result: "Hub routes to filesystem server, starts it if needed, returns result"
    why_it_matters: |
      The agent never configures anything. It just asks for capabilities.
      This is the hub's core value proposition - capability on demand.

  - scenario: "New project setup"
    context: "Starting work on a project that needs GitHub and Postgres access"
    action: "mcp-hub warm github postgres"
    result: "Both servers pre-started, ready for instant response"
    why_it_matters: |
      First request to a cold server can take 5-10 seconds. Pre-warming
      eliminates this latency when you know what you'll need.

  - scenario: "Debugging server issues"
    context: "GitHub tool calls are failing mysteriously"
    action: "mcp-hub logs github -f"
    result: "See real-time server logs, identify auth token expiration"
    why_it_matters: |
      MCP servers are black boxes without centralized logging.
      Hub makes debugging tractable.

  - scenario: "Project-specific database"
    context: "Project needs different Postgres database than global default"
    action: "Create .daedalos/mcp.yaml with postgres.config.database override"
    result: "Hub uses project-specific config when in that directory"
    why_it_matters: |
      Global defaults + local overrides. DRY without inflexibility.

  - scenario: "Tool discovery"
    context: "Developer wants to know what capabilities are available"
    action: "mcp-hub tools --json | jq '.[] | .name'"
    result: "Complete list of available tools across all servers"
    why_it_matters: |
      Discovery enables exploration. Without it, developers only use
      tools they already know about.

decisions:
  - choice: "Hub is a daemon, not a proxy library"
    why: |
      A daemon provides process isolation, resource management, and
      persistence. Servers can crash without taking down the agent.

      The alternative - embedding server management in each agent -
      means every agent reimplements lifecycle management, and servers
      get restarted per-agent instead of shared.
    alternatives:
      - option: "Library that each agent imports"
        rejected_because: "No sharing between agents, each manages its own servers"
      - option: "Sidecar process per agent"
        rejected_because: "Still duplicates server instances, wastes resources"
      - option: "Serverless/on-demand spawning"
        rejected_because: "Latency on first request, no warm pool benefit"

  - choice: "Tool routing by name, not explicit server selection"
    why: |
      Agents shouldn't need to know which server provides which tool.
      "read_file" should just work. The hub maintains the mapping.

      This abstraction means servers can be swapped without changing
      agent code. Different filesystem implementation? Update hub config,
      agents unchanged.
    alternatives:
      - option: "Explicit server.tool naming (github.create_issue)"
        rejected_because: "Leaks implementation detail, agents coupled to server names"
      - option: "Capability-based routing"
        rejected_because: "Over-engineered, tool names are already capabilities"

  - choice: "YAML config with environment variable expansion"
    why: |
      YAML is readable and widely understood. Environment variable
      expansion (${GITHUB_TOKEN}) keeps secrets out of config files.

      This matches how developers already think about configuration.
    alternatives:
      - option: "JSON config"
        rejected_because: "No comments, worse for documentation-in-config"
      - option: "TOML config"
        rejected_because: "Less common, adds learning curve for marginal benefit"
      - option: "Environment-only config"
        rejected_because: "Doesn't scale to complex server configurations"

  - choice: "On-demand server startup with warm pool"
    why: |
      Most servers sit idle most of the time. Starting all servers
      at hub start wastes resources. Starting per-request adds latency.

      Warm pool is the compromise: frequently-used servers stay running,
      rare ones start on-demand. Best of both worlds.
    alternatives:
      - option: "All servers always running"
        rejected_because: "Memory hog, wasteful for rarely-used servers"
      - option: "Pure on-demand (no pool)"
        rejected_because: "Unacceptable latency on first request"
      - option: "User explicitly manages which servers run"
        rejected_because: "Cognitive load, defeats the 'invisible infrastructure' goal"

  - choice: "Unix socket as primary interface, HTTP optional"
    why: |
      Unix sockets are faster than HTTP for local communication and
      provide built-in access control via filesystem permissions.

      HTTP is available for remote scenarios or debugging, but local
      agents should use the socket.
    alternatives:
      - option: "HTTP only"
        rejected_because: "Unnecessary overhead for local IPC"
      - option: "gRPC"
        rejected_because: "Adds complexity, MCP protocol is already JSON-RPC"

anti_patterns:
  - pattern: "Configuring MCP servers per-project when global would work"
    why_bad: |
      If every project has its own mcp-hub config with the same servers,
      you've recreated the fragmentation problem hub was meant to solve.

      Use global config for common servers (filesystem, github).
      Use project config only for project-specific needs (custom server,
      different database).

  - pattern: "Running mcp-hub call for every agent request"
    why_bad: |
      The CLI is for humans and debugging. Agents should connect to
      the hub via MCP protocol directly, not shell out to the CLI.

      CLI adds process spawn overhead on every call. Direct connection
      maintains context and is much faster.

  - pattern: "Pre-warming everything 'just in case'"
    why_bad: |
      "mcp-hub warm *" defeats the purpose of on-demand startup.
      You're back to wasting resources on idle servers.

      Warm only what you know you'll need. Let the pool handle the rest.

  - pattern: "Ignoring server health checks"
    why_bad: |
      A crashed server stays crashed until hub restarts it. If you
      never check status, you get mysterious tool failures.

      Integrate "mcp-hub status" into your workflow or monitoring.

  - pattern: "Storing secrets in mcp-hub config directly"
    why_bad: |
      Config files get committed to git, shared, backed up in plain text.
      Secrets in config = secrets exposed.

      Use environment variables (${GITHUB_TOKEN}) or keyring integration.
      Never raw secrets in YAML.

connects_to:
  - component: agent
    relationship: |
      Agent templates can specify which MCP servers to warm before
      spawning. The agent sends requests to hub, hub routes to servers.

      When agent workflow starts, it can "mcp-hub warm" the servers
      that workflow will need.

  - component: loop
    relationship: |
      Loops often need MCP tools (filesystem operations, API calls).
      Hub provides these tools transparently to the agent running
      inside the loop.

      Loop's orchestration can include mcp-hub warm in setup phase.

  - component: project
    relationship: |
      Project info can suggest which MCP servers are relevant based
      on detected technologies (Python project â†’ suggest Postgres if
      sqlalchemy detected).

      Hub can auto-configure based on project detection.

  - component: secrets
    relationship: |
      Hub authentication can pull from secrets vault instead of
      environment variables. "mcp-hub auth github" stores token
      in encrypted secrets, hub retrieves at runtime.

  - component: gates
    relationship: |
      Gates can control which MCP tools agents are allowed to use.
      Hub respects gate permissions - if an agent is denied network
      access, hub won't route to servers that make network calls.

metrics:
  success_criteria:
    - "Agent tool requests succeed > 99% when server is healthy"
    - "Cold start to first response < 5 seconds for any server"
    - "Warm server response < 200ms for simple tools"
    - "Hub restart doesn't lose running server state"
    - "Developers stop thinking about MCP server configuration"

  failure_indicators:
    - "Agents still configuring MCP servers directly"
    - "Per-project mcp.yaml files duplicating global config"
    - "Server crashes go unnoticed until agent fails"
    - "Warm pool bloats to consume excessive memory"
    - "Tool routing returns wrong server (name collision)"
