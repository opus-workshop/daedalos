name: remote
version: 1.0
created: 2025-01-11

intent: |
  Local machine is a lie. Real work happens across machines.

  Development increasingly spans locations: laptop for coding, server
  for GPU training, cloud instance for deployment testing. SSH handles
  the connection, but connection isn't enough. You need seamless
  movement of code, state, and sessions.

  The deeper insight: AI agents will work on remote machines MORE than
  humans do. An agent might spin up a cloud instance, run experiments,
  and report back. The agent doesn't have fingers to type SSH commands
  manually. It needs a clean interface to remote operations.

  Remote is SSH-plus: connection management (so you stop retyping
  connection strings), file sync (so code moves with you), tunnels
  (so services reach across machines), and remote dev sessions
  (so the whole environment follows).

  Human equivalent: "I have all these machines I use. Remember how to
  reach them, move my stuff around, and let me work there like I do here."

constraints:
  - SSH-based (no proprietary protocols, works everywhere)
  - Stored hosts in simple JSON (human-readable, git-able)
  - Connect works even without stored host (falls back to direct SSH)
  - Sync uses rsync (efficient, resumable, widely available)
  - Tunnels support both directions (local->remote, remote->local)
  - Status checks are quick (< 2s timeout per host)
  - No daemon required (stateless operations)

interface:
  commands:
    connect:
      args: "<HOST> [SSH_ARGS...]"
      returns: "Interactive SSH session to host"
      example: "remote connect prod"

    add:
      args: "<NAME>"
      returns: "Interactive prompt to add new host configuration"
      example: "remote add staging"

    remove:
      args: "<NAME>"
      returns: "Removes host from configuration"
      example: "remote remove old-server"

    list:
      args: ""
      returns: "All configured hosts with details"
      example: "remote list"

    edit:
      args: "[NAME]"
      returns: "Opens hosts.json in editor"
      example: "remote edit"

    sync:
      args: "<HOST> [PATH] [--to|--from] [--exclude PATTERN] [--dry-run]"
      returns: "Syncs files between local and remote"
      example: "remote sync prod . --to"

    tunnel:
      args: "<HOST> --local PORT --remote PORT [--reverse] [--background]"
      returns: "Creates SSH tunnel"
      example: "remote tunnel prod --local 3000 --remote 3000"

    exec:
      args: "<HOST> <COMMAND...>"
      returns: "Executes command on remote"
      example: "remote exec prod 'docker ps'"

    copy-id:
      args: "<HOST>"
      returns: "Copies SSH key to remote for passwordless login"
      example: "remote copy-id prod"

    status:
      args: ""
      returns: "Connectivity status for all hosts"
      example: "remote status"

    dev:
      args: "<HOST>"
      returns: "Starts remote dev session (tmux on remote)"
      example: "remote dev prod"

  options:
    to: "--to: Sync direction local to remote (default)"
    from: "--from: Sync direction remote to local"
    exclude: "--exclude PATTERN: Exclude files from sync"
    dry_run: "--dry-run: Show what would sync without syncing"
    local: "--local PORT: Local port for tunnel"
    remote_port: "--remote PORT: Remote port for tunnel"
    reverse: "--reverse: Reverse tunnel direction"
    background: "--background: Run tunnel in background"

  exit_codes:
    0: "Success"
    1: "Host not found or connection failed"
    2: "Sync failed"
    3: "Tunnel creation failed"

examples:
  - scenario: "Agent needs GPU for training"
    context: "Local machine is CPU-only, cloud instance has GPU"
    action: |
      remote sync gpu-server . --to
      remote exec gpu-server 'cd project && python train.py'
      remote sync gpu-server ./results --from
    result: "Code synced, training run remotely, results retrieved"
    why_it_matters: |
      Agent can orchestrate remote resources programmatically.
      No manual SSH sessions. The agent treats the GPU server
      as an extension of its capabilities.

  - scenario: "Service debugging on production"
    context: "Production database, need to inspect locally"
    action: "remote tunnel prod --local 5432 --remote 5432"
    result: "Local postgres client connects to production DB"
    why_it_matters: |
      Production data stays on production. Only the connection tunnels.
      Debug without copying sensitive data locally.

  - scenario: "Persistent remote session"
    context: "Long-running process on server, don't want to lose it"
    action: "remote dev server"
    result: "Connects to or creates tmux session named 'dev'"
    why_it_matters: |
      Network drops don't kill your process. Come back hours later,
      tmux session is still there. Essential for unreliable connections.

  - scenario: "Multi-machine deployment"
    context: "Deploy same code to staging and production"
    action: |
      remote sync staging . --to
      remote exec staging 'docker compose up -d'
      remote sync prod . --to
      remote exec prod 'docker compose up -d'
    result: "Code deployed to both environments"
    why_it_matters: |
      Scriptable deployments. Agent can automate this.
      Same commands work for any host in the config.

  - scenario: "New server setup"
    context: "Got access to new server, need to configure"
    action: |
      remote add newserver
      remote copy-id newserver
      remote connect newserver
    result: "Server added, key installed, connected"
    why_it_matters: |
      One-time setup, then forever easy access.
      copy-id eliminates password prompts for all future connections.

decisions:
  - choice: "Store hosts in JSON, not SSH config"
    why: |
      SSH config (~/.ssh/config) is the standard, but:
      - It's shared with other tools (conflicts)
      - Format is arcane (not easily parseable)
      - Hard to add custom metadata (project paths, etc.)

      JSON is simple, parseable, tool-friendly. Hosts file is
      ~/.config/daedalos/remote/hosts.json - dedicated, no conflicts.

      For users who want SSH config, they can still use host names
      directly: "remote connect myhost" works if myhost is in SSH config.
    alternatives:
      - option: "Use SSH config directly"
        rejected_because: "Shared with other tools, format hard to parse, no custom fields"
      - option: "SQLite database"
        rejected_because: "Overkill, not human-editable, harder to version control"
      - option: "YAML/TOML config"
        rejected_because: "JSON is sufficient and Python's json module is built-in"

  - choice: "Fallback to direct SSH for unknown hosts"
    why: |
      "remote connect user@192.168.1.100" should just work.
      Users don't want to add hosts for one-off connections.

      The config is for frequently-used hosts. Unknown hosts
      pass through to SSH directly. No gatekeeping.
    alternatives:
      - option: "Require all hosts in config"
        rejected_because: "Friction for quick connections, not how SSH works"
      - option: "Auto-add unknown hosts"
        rejected_because: "Pollutes config with one-off connections"

  - choice: "rsync for file sync"
    why: |
      rsync is the gold standard for remote sync:
      - Delta transfer (only changed bytes)
      - Compression in transit
      - Resumable
      - Handles permissions, symlinks
      - Universally available

      scp is simpler but lacks delta transfer.
      Custom sync is reinventing the wheel.
    alternatives:
      - option: "scp"
        rejected_because: "No delta transfer, can't resume, slower for updates"
      - option: "git push/pull"
        rejected_because: "Only works for git repos, doesn't handle untracked files"
      - option: "Custom sync implementation"
        rejected_because: "rsync is battle-tested, why reinvent?"

  - choice: "Default sync direction is local to remote"
    why: |
      "I'm developing locally, want to run on remote" is the common case.
      Making --to the default means less typing for the common case.

      --from for the reverse is explicit and memorable.

      The path on remote defaults to host config's 'path' field,
      so frequently "remote sync host" is all you need.
    alternatives:
      - option: "Require explicit direction always"
        rejected_because: "Verbose for common case"
      - option: "Auto-detect based on path"
        rejected_because: "Too magical, easy to get wrong, confusing"

  - choice: "Dev command uses tmux"
    why: |
      Remote sessions die when SSH disconnects. tmux persists.

      Creating/attaching to a named session ('dev') means:
      - First time: creates session
      - Next time: attaches to existing

      This makes remote work resilient to network issues.
      The session name is predictable (always 'dev'), easy to remember.
    alternatives:
      - option: "Plain SSH"
        rejected_because: "Session dies on disconnect, loses work"
      - option: "screen instead of tmux"
        rejected_because: "tmux is more modern, better defaults, more features"
      - option: "Custom persistent session"
        rejected_because: "tmux already solves this perfectly"

  - choice: "2-second timeout for status checks"
    why: |
      Status checks all hosts for connectivity. A dead host shouldn't
      make you wait forever.

      2 seconds is enough for most connections, fast enough to feel
      responsive. nc (netcat) with timeout is lightweight.

      Status is informational - a timeout doesn't prevent other operations.
    alternatives:
      - option: "No timeout"
        rejected_because: "One dead host blocks the whole status command"
      - option: "Longer timeout (10s)"
        rejected_because: "Status check becomes tediously slow"
      - option: "Parallel checks"
        rejected_because: "Complexity for marginal gain, serial is fine"

anti_patterns:
  - pattern: "Storing passwords in host config"
    why_bad: |
      JSON config is plaintext. Passwords in plaintext = disaster.
      Use SSH keys (copy-id command) or SSH agent.

      The config stores key PATH, not key contents.
      Password-based SSH should be temporary during setup only.

  - pattern: "Syncing without checking .gitignore"
    why_bad: |
      "remote sync" sends everything. Including node_modules (500MB),
      __pycache__, build artifacts, etc.

      Use --exclude for large directories, or better, make the
      remote pull from git instead of pushing files directly.

  - pattern: "Long-running tunnels in foreground"
    why_bad: |
      "remote tunnel prod ..." blocks your terminal.
      Use --background for tunnels you want to keep running.

      Foreground is fine for debugging, but not for persistent tunnels.

  - pattern: "Remote exec for interactive commands"
    why_bad: |
      "remote exec prod vim file.txt" won't work well.
      exec is for commands that run and return, not interactive sessions.

      Use "remote dev" or "remote connect" for interactive work.

  - pattern: "Assuming remote has same tools"
    why_bad: |
      "remote exec server 'container dev'" assumes container tool exists.
      Remote machines may have different tool setups.

      Check remote capabilities or sync tools first.

connects_to:
  - component: container
    relationship: |
      Remote syncs code to server. Container runs the environment.

      remote sync server . -> remote exec server 'container build'

      Typical deployment: sync code, build container, run.

  - component: backup
    relationship: |
      Backup can push to remote storage:
      backup create --remote server

      Backups stored offsite are safer than local-only.

  - component: env
    relationship: |
      Env sets local environment. Remote dev sessions may need same vars.

      Consider: remote exec inherits local env? Or separate remote env?
      Currently separate - remote has its own environment.

  - component: secrets
    relationship: |
      SSH keys can be managed by secrets vault.
      But typically SSH keys are in ~/.ssh/ (standard location).

      Future: secrets integration for SSH key management?

  - component: journal
    relationship: |
      Remote logs connections for audit:
      "Connected to remote: prod" with timestamp

      Useful for tracking what remotes were accessed and when.

  - component: session
    relationship: |
      Session saves/restores terminal state.
      Remote dev uses tmux for similar persistence on remote.

      Different mechanisms, same goal: don't lose work on disconnect.

metrics:
  success_criteria:
    - "Connect to stored host in < 3 seconds"
    - "Sync respects excludes (no node_modules transferred)"
    - "Tunnel works bidirectionally without issues"
    - "Status check completes in < 10 seconds for 5 hosts"
    - "Dev session survives network reconnection"

  failure_indicators:
    - "Users maintain separate SSH config instead of using remote"
    - "Sync transfers too much (excludes not working)"
    - "Tunnels drop silently (no retry or notification)"
    - "Status hangs on unreachable hosts"
    - "Dev session loses state on reconnect (tmux not persisting)"
